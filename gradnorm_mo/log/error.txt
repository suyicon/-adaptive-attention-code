/var/spool/slurm/d/job03398/slurm_script: line 8: activate: No such file or directory
/home/mc35291/repo/attn_code/gradnorm_mo/main.py:48: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/build/aten/src/ATen/core/TensorBody.h:486.)
  self.w.grad.data = self.w.grad.data * 0.0
Traceback (most recent call last):
  File "/home/mc35291/repo/attn_code/gradnorm_mo/main.py", line 413, in <module>
    train_model(model, args)
  File "/home/mc35291/repo/attn_code/gradnorm_mo/main.py", line 263, in train_model
    Gradnormloss.additional_forward_and_backward(shared_weight,args.optimizer)
  File "/home/mc35291/repo/attn_code/gradnorm_mo/main.py", line 48, in additional_forward_and_backward
    self.w.grad.data = self.w.grad.data * 0.0
AttributeError: 'NoneType' object has no attribute 'data'
